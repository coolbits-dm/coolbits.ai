
1) Prompt → @oCL — Create /api/costs/today (file write)

Mesaj (trimite-l ca atare lui @oCL):

Scrie fișierul andy-web/app/api/costs/today/route.ts cu conținutul de mai jos (single-quoted here-string, fără expansiuni), apoi te oprești. Nu rula build/deploy încă.

@'
import { NextResponse } from "next/server";
import { estimateUSD } from "@/app/lib/cost";

async function getAccessToken(): Promise<string> {
  const r = await fetch("http://metadata/computeMetadata/v1/instance/service-accounts/default/token", {
    headers: { "Metadata-Flavor": "Google" },
    cache: "no-store",
  });
  if (!r.ok) throw new Error(`metadata token failed: ${r.status}`);
  const { access_token } = await r.json();
  return access_token;
}

export const dynamic = "force-dynamic";

export async function GET() {
  const started = Date.now();
  try {
    const project =
      process.env.GOOGLE_CLOUD_PROJECT || process.env.GCP_PROJECT || "";
    if (!project) throw new Error("no GCP project in env");

    // start-of-day UTC
    const now = new Date();
    const sod = new Date(Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate(), 0, 0, 0));
    const since = sod.toISOString();

    const token = await getAccessToken();
    let nextPageToken: string | undefined = undefined;
    let count = 0;
    let total = 0;
    const byModel: Record<string, number> = {};

    for (let page = 0; page < 20; page++) {
      const body = {
        resourceNames: [`projects/${project}`],
        filter:
          `timestamp >= "${since}" AND resource.type="cloud_run_revision" AND jsonPayload.t="openai_usage"`,
        orderBy: "timestamp desc",
        pageSize: 200,
        pageToken: nextPageToken,
      };

      const r = await fetch("https://logging.googleapis.com/v2/entries:list", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${token}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify(body),
      });
      if (!r.ok) throw new Error(`logging read failed: ${r.status}`);
      const j = await r.json();

      const entries = Array.isArray(j.entries) ? j.entries : [];
      for (const e of entries) {
        const p = e?.jsonPayload || {};
        const model = (p.model || p.model_sent || "unknown") as string;
        let est = Number(p.est_cost);
        if (!Number.isFinite(est) && p.usage) {
          // fallback: calc pe baza usage, folosind estimateUSD din lib
          try { est = estimateUSD(model, p.usage) || 0; } catch { est = 0; }
        }
        if (!Number.isFinite(est)) est = 0;
        total += est;
        count += 1;
        byModel[model] = (byModel[model] || 0) + est;
      }

      nextPageToken = j.nextPageToken;
      if (!nextPageToken) break;
    }

    return NextResponse.json(
      {
        ok: true,
        project,
        since,
        count,
        total_usd_est: Number(total.toFixed(6)),
        by_model: Object.fromEntries(Object.entries(byModel).map(([m, v]) => [m, Number((v as number).toFixed(6))])),
        ms: Date.now() - started,
      },
      { headers: { "Cache-Control": "no-store" } }
    );
  } catch (e: any) {
    return NextResponse.json(
      { ok: false, error: e?.message || "internal", ms: Date.now() - started },
      { status: 500, headers: { "Cache-Control": "no-store" } }
    );
  }
}
'@

2) Prompt → @oCL — Build + Deploy + Smoke (Approve gate)

Mesaj (trimite-l, apoi răspunde doar cu Approve când ești gata să ruleze):

Pregătește build+deploy+smoke. La „Approve” rulezi EXACT blocul de mai jos în pwsh extern și îmi dai DOAR ultima linie JSON.

# -------- vars --------
$P   = "coolbits-ai"
$R   = "europe-west3"
$WEB = "https://andy.coolbits.ai"
$CID = "271190369805-tstvodmh01grrrsc5543r00ffiekk7mo.apps.googleusercontent.com"
$ROOT = "$env:USERPROFILE\Desktop\coolbits\andy-web"
# ----------------------

Set-Location $ROOT
if (Test-Path package-lock.json) { npm ci --no-audit --fund=false } else { npm i --no-audit --fund=false }
npm run build

gcloud run deploy andy-web `
  --project $P --region $R --source $ROOT `
  --ingress internal-and-cloud-load-balancing `
  --service-account "andy-web@$P.iam.gserviceaccount.com" `
  --set-env-vars "GATEWAY_URL=https://andy-gateway-ygpdeb546q-ey.a.run.app,OPENAI_SECRET=openai_api_key" `
  --cpu=1 --memory=512Mi --max-instances=3 --quiet

# Smoke:
$T = (gcloud auth print-identity-token --audiences=$CID --quiet).Trim()
$HEAD = (curl.exe -s -o NUL -w "%{http_code}" $WEB).Trim()            # LB warmup (așteptăm 302)
$INFO = (curl.exe -s -H "Authorization: Bearer $T" "$WEB/api/info")
$COST = (curl.exe -s -H "Authorization: Bearer $T" "$WEB/api/costs/today")

# rezultat compact:
$payload = [ordered]@{
  head = $HEAD
  info = try { $INFO | ConvertFrom-Json } catch { $null }
  costs_today = try { $COST | ConvertFrom-Json } catch { $null }
}
$payload | ConvertTo-Json -Compress | Write-Output


Cost API OpenAI în acest smoke: 0 (nu chemăm /api/complete). Doar deploy + 2 GET-uri interne.

3) (Opțional) Prompt → @oCL — Cost sanity ping (mini)

Dacă vrei un ping real la OpenAI (cu cost sub $0.001), folosește:

Pe „Approve” rulezi blocul. ONE-SHOT ONLY. Fără rezumat AI.

$WEB="https://andy.coolbits.ai"
$CID="271190369805-tstvodmh01grrrsc5543r00ffiekk7mo.apps.googleusercontent.com"
$T=(gcloud auth print-identity-token --audiences=$CID --quiet).Trim()
$B=@{ model="gpt-5-mini"; input="ping"; max_output_tokens=40 } | ConvertTo-Json -Compress
$R=curl.exe -s -H "Authorization: Bearer $T" -H "Content-Type: application/json" -d $B "$WEB/api/complete"
$j=$R|ConvertFrom-Json
$am = $j.model ?? $j.model_sent ?? "unknown"
$pt = $j.usage?.prompt_tokens ?? 0
$ot = $j.usage?.output_tokens ?? 0
$est = $j.est_cost ?? 0
@{model=$am; pt=$pt; ot=$ot; usd_est=[math]::Round([double]$est,6)} | ConvertTo-Json -Compress | Write-Output

4) Note scurte (de ce facem așa)

/api/costs/today citește Cloud Logging cu jsonPayload.t="openai_usage" (exact logul pe care l-ai introdus în /api/complete) și însumează est_cost (sau calculează fallback din usage).

Flow-ul de build+deploy+smoke nu atinge OpenAI; e safe ca buget.

Când vrei să testezi un „request real” la model, folosește Prompt 3 (mini, 40 tokens max).

Dacă e ok, trimite Prompt 1 lui @oCL, apoi Approve pentru Prompt 2. După ce avem JSON-ul de la smoke, decidem următorul mic pas (ex. card UI cu costurile de azi).