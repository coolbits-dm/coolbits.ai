super — hai s-o facem “de producție”, dar cu pași mici, clari, și ieftini. Mai jos ai:

ce fișiere adăugăm/modificăm (și de ce),

3 prompt-uri scurte pentru @oCL (PowerShell one-shot, fără interactiv),

ce verificăm după fiecare pas.

Dacă rulezi exact blocurile @oCL, obții panoul + estimator + logare costuri cu aprobare umană “Approve” (flow A), fără să mai gonflezi usage.

Plan concret (repo andy-web)
A. Fișiere noi / modificate

app/api/complete/route.ts (MOD)

Ce adăugăm:

cap max_output_tokens (deja ai),

reasoning_effort: "minimal" doar pt familia gpt-5 (deja ai),

PRICING (map) + cost_est,

logging structurat (o singură linie JSON) → Cloud Run Logs,

header X-Model-Active în răspuns.

Scop: sursa unică de adevăr pt „ce model a rulat + câți tokeni + ~$”.

app/api/models/route.ts (EXISTENT)

Ce adăugăm: câmp pricing (in/out per 1M) ca să fie consumat și de UI/estimate.

app/api/estimate/route.ts (EXISTENT)

Ce adăugăm: deja ai clamp + rate-limit + X-RateLimit-Remaining. OK așa.

app/api/info/route.ts (NOU) – heartbeat

Ce expune: {ok, health(ms), service, revision, project, gateway_url}. (ai deja; îl păstrăm)

app/components/StatusCard.tsx (NOU) – card heartbeat

Ce face: citește /api/info, arată OK/ERR, latență, revizie. (ai deja; îl păstrăm)

app/components/AndyConsole.tsx (EXISTENT)

Ce adăugăm: sub pre arată sumar din usage + est_cost dacă vin în răspuns.

app/components/EstimatorPanel.tsx (EXISTENT)

Ce adăugăm: deja ai remaining din header. OK așa.

app/page.tsx (MOD)

Ce păstrăm: grid cu Status + Routes + Console + link la /api/models și /api/estimate.

app/lib/cost.ts (NOU)

Ce conține: map PRICING sincron cu /api/models + util estimateUSD(usage, model) — DRY.

(opțional) app/api/costs/today/route.ts

MVP: nu agregăm server-side (ca să rămânem ieftin). Folosim Cloud Logging query din CLI pentru raport rapid (vezi Pasul C). Poți adăuga endpoint mai târziu, dacă vrei re-sumarizare server-side.

B. Prompt #1 pentru @oCL — “Patch + Build + Deploy”

Ce face: scrie (sau actualizează) fișierele minime de mai sus (patch mic la complete/route.ts ca să logheze cost + header), rebuild, deploy Cloud Run (ingress LB/IAP).
Rulare: îi dai Approve și rulezi un singur bloc PowerShell (folosește here-strings single-quoted @' … '@ ca să nu crape).

Copiază integral la @oCL:

[@oCL EXEC] Patch cost+logging + Rebuild + Deploy (≤700 in, ≤150 out). 
Rulează EXACT blocul, returnează doar ultima linie JSON.

$P="coolbits-ai"; $R="europe-west3"; $S="andy-web"
$ROOT="$env:USERPROFILE\Desktop\coolbits\andy-web"

# 1) Patch cost utils (lib/cost.ts)
$newCost = @'
export type Pricing = { in: number; out: number };
export const PRICING: Record<string, Pricing> = {
  "gpt-5":      { in: 1.25, out: 10.00 },
  "gpt-5-mini": { in: 0.25, out: 2.00 },
  "gpt-4.1-mini": { in: 0.40, out: 1.60 },
};
export function estimateUSD(usage: any, model: string): number {
  if (!usage || !model || !PRICING[model]) return 0;
  const pt = Number(usage.prompt_tokens||0);
  const ot = Number(usage.output_tokens||0);
  const r = PRICING[model];
  return ((pt * r.in) + (ot * r.out)) / 1_000_000;
}
'@
ni $ROOT/app/lib -it Directory -Force | Out-Null
sc -Path "$ROOT/app/lib/cost.ts" -Enc UTF8 -NoNewline -Value $newCost

# 2) Patch api/complete (injectează cost + log + header)
$complete = gc "$ROOT/app/api/complete/route.ts" -Raw
$complete = $complete -replace 'export async function POST\([^\)]*\)\s*\{','export async function POST(req: Request){'
$needle = 'return NextResponse.json({ ok:r.ok, status:r.status, model, output_text:text, usage, ms, raw: body\?\.debug \? raw : undefined });'
if($complete -match [regex]::Escape($needle)){
  $injected = @'
    // ---- cost & logging injection
    const { estimateUSD } = await import("@/app/lib/cost");
    const est_cost = estimateUSD(usage, model);
    console.log(JSON.stringify({t:"openai_usage", model_sent:model, model_returned: raw?.model||null, usage, est_cost, ms, at: new Date().toISOString()}));
    const resp = NextResponse.json({ ok:r.ok, status:r.status, model, model_sent:model, output_text:text, usage, est_cost, ms, raw: body?.debug ? raw : undefined });
    if (model) resp.headers.set("X-Model-Active", model);
    return resp;
'@
  $complete = $complete -replace [regex]::Escape($needle), $injected
  sc -Path "$ROOT/app/api/complete/route.ts" -Enc UTF8 -NoNewline -Value $complete
}

# 3) Build + Deploy
sl $ROOT
if (Test-Path package-lock.json) { npm ci --no-audit --fund=false } else { npm i --no-audit --fund=false }
npm run build

gcloud run deploy $S --project $P --region $R --source $ROOT `
  --ingress internal-and-cloud-load-balancing `
  --service-account "$S@$P.iam.gserviceaccount.com" `
  --set-env-vars "GATEWAY_URL=https://andy-gateway-ygpdeb546q-ey.a.run.app,OPENAI_SECRET=openai_api_key" `
  --cpu=1 --memory=512Mi --max-instances=3 --quiet

$rev = gcloud run services describe $S --region $R --format="value(status.latestReadyRevisionName)"
"{""rev"":""$rev""}"


Așteptat la final: {"rev":"andy-web-000xx-..."}

C. Prompt #2 pentru @oCL — “Smoke + Cost sanity”

Ce face: lovește LB/IAP, apelează /api/complete cu gpt-5-mini și calculează local $ pe baza usage + PRICING (trece și X-Model-Active).
Rulare: Approve → un singur bloc PS → 2 linii: JSON smoke + format compact.

[@oCL EXEC] Smoke (≤700 in, ≤150 out). Doar cele două linii finale.

$WEB="https://andy.coolbits.ai"
$CID="271190369805-tstvodmh01grrrsc5543r00ffiekk7mo.apps.googleusercontent.com"
$PRICING = @{ "gpt-5"=@{in=1.25;out=10.00}; "gpt-5-mini"=@{in=0.25;out=2.00}; "gpt-4.1-mini"=@{in=0.40;out=1.60} }

$T=(gcloud auth print-identity-token --audiences=$CID --quiet).Trim()
$H=(curl.exe -s -o NUL -w "%{http_code}" -H "Authorization: Bearer $T" "$WEB/api/proxy/health").Trim()
$K=(curl.exe -s -o NUL -w "%{http_code}" -H "Authorization: Bearer $T" "$WEB/api/proxy/task").Trim()

$BODY = @{ model="gpt-5-mini"; input="ping"; max_output_tokens=60 } | ConvertTo-Json -Compress
$R = curl.exe -s -D - -H "Authorization: Bearer $T" -H "Content-Type: application/json" -d $BODY "$WEB/api/complete"
$hdr,$json = ($R -split "(\r?\n){2}",2)
$j = $null; try { $j = $json | ConvertFrom-Json } catch {}
$am = if ($hdr -match 'X-Model-Active:\s*(\S+)') { $Matches[1].Trim() } elseif ($j.model) { $j.model } elseif ($j.model_sent) { $j.model_sent } else { "unknown" }
$pt=[int]($j.usage.prompt_tokens|?{$_}) ; $ot=[int]($j.usage.output_tokens|?{$_})
$rate=$PRICING[$am]; $usd=if($rate){ (($pt*$rate.in)+($ot*$rate.out))/1e6 } else {0}
$smoke = @{ health=[int]$H; task=[int]$K; model=$am; prompt_tokens=$pt; output_tokens=$ot; usd_est=$usd }
$smoke_json = $smoke | ConvertTo-Json -Compress
$tag = "[am=$am]-[~to=$ot]-[~$={0:N4}]" -f $usd
$smoke_json; $tag


Așteptat:
{"health":403,"task":403,"model":"gpt-5-mini","prompt_tokens":...,"output_tokens":...,"usd_est":...}
[am=gpt-5-mini]-[~to:X]-[~$=0.00YY]

Notă: 403 pe /proxy e OK dacă e privat; important e să vedem modelul și costul.

D. Prompt #3 pentru @oCL — “Log query cost (Cloud Logging)”

Ce face: trage ultimele 20 de intrări t="openai_usage" scrise de api/complete, calculează suma $ local, afișează un mic raport.

[@oCL EXEC] Cost report (≤700 in, ≤150 out). Doar cele 2 linii finale.

$P="coolbits-ai"
$F='jsonPayload.t="openai_usage" AND resource.type="cloud_run_revision" AND resource.labels.service_name="andy-web"'
$rows = gcloud logging read --project $P --freshness=24h --limit=20 --format=json --order=desc --filter="$F" | ConvertFrom-Json
$sum = 0.0
foreach($r in $rows){
  $est = $r.jsonPayload.est_cost
  if($est -is [double]){ $sum += $est }
}
$cnt = ($rows|measure).Count
$report = @{ entries=$cnt; sum_usd=[math]::Round($sum,6) } | ConvertTo-Json -Compress
$tag = "[24h-entries=$cnt]-[~$={0:N4}]" -f $sum
$report; $tag


Așteptat:
{"entries":N,"sum_usd":0.00xxx}
[24h-entries=N]-[~$=0.00YY]

Ce verifici după

/api/complete răspunde cu model, model_sent, usage, est_cost, header X-Model-Active.

În Cloud Logging, vezi linii JSON cu t:"openai_usage".

Smoke arată model=gpt-5-mini și cost mic (sub un cent).

Dashboard andy.coolbits.ai: Status OK, Console funcțională, Estimator cu X-RateLimit-Remaining.

De ce e safe/ieftin

default gpt-5-mini, reasoning minimal, cap max_output_tokens, și ALLOWED strict;

logare cost la fiecare răspuns;

estimate endpoint pentru pre-calcul;

rate-limit pe estimate;

Approve flow (Opțiunea A) — nimic nu rulează fără „Approve”.

Ce urmează (opțional, când vrei)

/api/costs/today (server-side aggregation) – putem adăuga Firestore sau BigQuery mai târziu;

UI Approvals (modal “Approve”) – Opțiunea B;

Guard de cost /timeout pe /api/complete (ex: stop dacă want_out > X sau dacă est_cost > threshold).

dacă ești ok, dă-i Approve la Prompt #1 în @oCL; după deploy rulăm #2 și #3 ca sanity/cost.

(estimări această replică: ~450–550 to out ⇒ ~$0.0009–$0.0011 pe gpt-5-mini)